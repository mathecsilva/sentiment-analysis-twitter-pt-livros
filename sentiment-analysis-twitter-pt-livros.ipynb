{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Goals\n",
    "* O objetivo deste notebook é obter mensagens da rede social Twitter, para analisar o sentimento geral sobre um produto na lingua portuguesa (pt).\n",
    "* Neste caso será considerado o produto 'livros'.\n",
    "* Para esse cálculo será utilizado inteligência artifical com NLP.\n",
    "\n",
    "#### NLP\n",
    "* NLP (Natural Linguage Processing) explora habilidades computacionais para entender e classificar textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text file keys \n",
    "txtKeys = open('ktw.txt', 'r').read().splitlines()\n",
    "api_key = txtKeys[0]\n",
    "api_key_secret = txtKeys[1]\n",
    "api_token = txtKeys[2]\n",
    "api_token_secret = txtKeys[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API authentication \n",
    "auth = tweepy.OAuthHandler(consumer_key=api_key, consumer_secret=api_key_secret)\n",
    "auth.set_access_token(api_token, api_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API params\n",
    "search_query = 'livro' + ' -filter:retweets'\n",
    "tweet_amount = 2000\n",
    "tweets = tweepy.Cursor(api.search, q=search_query, lang='pt').items(tweet_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets list\n",
    "cols = set()\n",
    "allowed_types = [str, int]\n",
    "tw_data = []\n",
    "\n",
    "for tw in tweets:\n",
    "    tw_dict = dict(vars(tw))\n",
    "    tw_keys = tw_dict.keys()\n",
    "    filter_data = {}\n",
    "    for k in tw_keys:\n",
    "        try:\n",
    "            k_type = type(tw_dict[k])\n",
    "        except:\n",
    "            k_type = None\n",
    "        if k_type != None:\n",
    "            if k_type in allowed_types:\n",
    "                cols.add(k)\n",
    "                filter_data[k] = tw_dict[k]\n",
    "    tw_data.append(filter_data)\n",
    "\n",
    "header_cols = list(cols)\n",
    "#tw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_url', 'retweet_count', 'source', 'id_str',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id_str', 'id',\n",
       "       'in_reply_to_screen_name', 'quoted_status_id', 'in_reply_to_user_id',\n",
       "       'quoted_status_id_str', 'favorite_count', 'lang', 'text',\n",
       "       'in_reply_to_status_id_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweets Dataframe\n",
    "df = pd.DataFrame(tw_data, columns=header_cols)\n",
    "#df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Data\n",
    "df.drop(['in_reply_to_status_id_str', 'in_reply_to_screen_name',\n",
    "         'in_reply_to_user_id', 'id_str', 'in_reply_to_status_id',\n",
    "         'favorite_count', 'in_reply_to_user_id_str', 'lang', 'source',\n",
    "         'source_url']\n",
    "        , inplace=True\n",
    "        , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'text', 'retweet_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1391133798310547456</td>\n",
       "      <td>Eu tô DOIDA pra vocês conhecerem o primeiro li...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1391132383676616713</td>\n",
       "      <td>não sei oq é mais nojento\\n\\nse é a pessoa que...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>1391131038680719360</td>\n",
       "      <td>“Destruidor de mundos” está chegando! ⚔️ Até o...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1391132708529745921</td>\n",
       "      <td>FML, LEIAM HEAVEN, VCS NÃO VÃO SE ARREPENDER, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1391132795913781250</td>\n",
       "      <td>nada e são apenas vítimas dessa situação, entã...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "431  1391133798310547456  Eu tô DOIDA pra vocês conhecerem o primeiro li...   \n",
       "603  1391132383676616713  não sei oq é mais nojento\\n\\nse é a pessoa que...   \n",
       "780  1391131038680719360  “Destruidor de mundos” está chegando! ⚔️ Até o...   \n",
       "564  1391132708529745921  FML, LEIAM HEAVEN, VCS NÃO VÃO SE ARREPENDER, ...   \n",
       "555  1391132795913781250  nada e são apenas vítimas dessa situação, entã...   \n",
       "\n",
       "     retweet_count  \n",
       "431             18  \n",
       "603              9  \n",
       "780              9  \n",
       "564              7  \n",
       "555              6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample by retweets count\n",
    "df.sort_values('retweet_count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Regulary Expretions\n",
    "import nltk #Natural Linguage Toolkit\n",
    "from nltk import tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regulary Expretions\n",
    "def remove_re(expressions):\n",
    "    tweets_cl = []\n",
    "    for exp in expressions:\n",
    "        f_expre = re.sub('@\\S+', '', exp)\n",
    "        s_expre = re.sub('https\\S+', '', f_expre)\n",
    "        final_expre = s_expre.lower().replace('.', '').replace(',', '').replace('-','').replace('\\n', '').replace(')','').replace('(','').replace('#', '').replace('!', '').replace('?', '').replace(';', '').replace('[', '').replace(']', '') \n",
    "        tweets_cl.append(final_expre)\n",
    "    return(tweets_cl)\n",
    "\n",
    "df_list = list(df.text)\n",
    "tweets_cl = remove_re(df_list)\n",
    "#tweets_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "word_tokens = []\n",
    "for tk in tweets_cl:\n",
    "    #print(word_tokenize(tk, language='portuguese'))\n",
    "    word_tokens.append(word_tokenize(tk, language='portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "#stopwords\n",
    "token_filter = []\n",
    "for wt in word_tokens:\n",
    "    for wtk in wt:\n",
    "        if wtk not in stopwords:\n",
    "            token_filter.append(wtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
