{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Goals\n",
    "* O objetivo deste notebook é obter mensagens da rede social Twitter, para analisar o sentimento geral sobre um produto na lingua portuguesa (pt).\n",
    "* Neste caso será considerado o produto 'livros'.\n",
    "* Para esse cálculo será utilizado inteligência artifical com NLP.\n",
    "\n",
    "#### NLP\n",
    "* NLP (Natural Linguage Processing) explora habilidades computacionais para entender e classificar textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text file keys \n",
    "txtKeys = open('ktw.txt', 'r').read().splitlines()\n",
    "api_key = txtKeys[0]\n",
    "api_key_secret = txtKeys[1]\n",
    "api_token = txtKeys[2]\n",
    "api_token_secret = txtKeys[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API authentication \n",
    "auth = tweepy.OAuthHandler(consumer_key=api_key, consumer_secret=api_key_secret)\n",
    "auth.set_access_token(api_token, api_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API params\n",
    "search_query = 'livro' + ' -filter:retweets'\n",
    "tweet_amount = 10\n",
    "tweets = tweepy.Cursor(api.search, q=search_query, lang='pt').items(tweet_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets list\n",
    "cols = set()\n",
    "allowed_types = [str, int]\n",
    "tw_data = []\n",
    "\n",
    "for tw in tweets:\n",
    "    tw_dict = dict(vars(tw))\n",
    "    tw_keys = tw_dict.keys()\n",
    "    filter_data = {}\n",
    "    for k in tw_keys:\n",
    "        try:\n",
    "            k_type = type(tw_dict[k])\n",
    "        except:\n",
    "            k_type = None\n",
    "        if k_type != None:\n",
    "            if k_type in allowed_types:\n",
    "                cols.add(k)\n",
    "                filter_data[k] = tw_dict[k]\n",
    "    tw_data.append(filter_data)\n",
    "\n",
    "header_cols = list(cols)\n",
    "#tw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['in_reply_to_status_id', 'lang', 'retweet_count', 'favorite_count',\n",
       "       'in_reply_to_status_id_str', 'id_str', 'in_reply_to_user_id_str', 'id',\n",
       "       'in_reply_to_user_id', 'in_reply_to_screen_name', 'source',\n",
       "       'source_url', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweets Dataframe\n",
    "df = pd.DataFrame(tw_data, columns=header_cols)\n",
    "#df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Data\n",
    "df.drop(['in_reply_to_status_id_str', 'in_reply_to_screen_name',\n",
    "         'in_reply_to_user_id', 'id_str', 'in_reply_to_status_id',\n",
    "         'favorite_count', 'in_reply_to_user_id_str', 'lang', 'source',\n",
    "         'source_url']\n",
    "        , inplace=True\n",
    "        , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'text', 'retweet_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391135563932131329</td>\n",
       "      <td>comprei um livro lindo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391135557221236742</td>\n",
       "      <td>3 surtos diferentes com o mesmo livro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391135543862439938</td>\n",
       "      <td>@zoyalinabot Eu faço quando o livro é pra vest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391135542633504768</td>\n",
       "      <td>Meu livro chegouuuuu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391135540221710336</td>\n",
       "      <td>@zoyalinabot Uma vibe de quem ler livro e faz ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1391135563932131329                             comprei um livro lindo   \n",
       "1  1391135557221236742              3 surtos diferentes com o mesmo livro   \n",
       "2  1391135543862439938  @zoyalinabot Eu faço quando o livro é pra vest...   \n",
       "3  1391135542633504768                               Meu livro chegouuuuu   \n",
       "4  1391135540221710336  @zoyalinabot Uma vibe de quem ler livro e faz ...   \n",
       "\n",
       "   retweet_count  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample by retweets count\n",
    "df.sort_values('retweet_count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Regulary Expretions\n",
    "import nltk #Natural Linguage Toolkit\n",
    "from nltk import tokenize\n",
    "from nltk import word_tokenize\n",
    "#from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regulary Expretions\n",
    "def remove_re(expressions):\n",
    "    tweets_cl = []\n",
    "    for exp in expressions:\n",
    "        f_expre = re.sub('@\\S+', '', exp)\n",
    "        s_expre = re.sub('https\\S+', '', f_expre)\n",
    "        final_expre = s_expre.lower().replace('.', '').replace(',', '').replace('-','').replace('\\n', '').replace(')','').replace('(','').replace('#', '').replace('!', '').replace('?', '').replace(';', '').replace('[', '').replace(']', '') \n",
    "        tweets_cl.append(final_expre)\n",
    "    return(tweets_cl)\n",
    "\n",
    "df_list = list(df.text)\n",
    "tweets_cl = remove_re(df_list)\n",
    "#tweets_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "word_tokens = []\n",
    "for tk in tweets_cl:\n",
    "    #print(word_tokenize(tk, language='portuguese'))\n",
    "    word_tokens.append(word_tokenize(tk, language='portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "#stopwords\n",
    "token_filter = []\n",
    "for wt in word_tokens:\n",
    "    for wtk in wt:\n",
    "        if wtk not in stopwords:\n",
    "            token_filter.append(wtk)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
